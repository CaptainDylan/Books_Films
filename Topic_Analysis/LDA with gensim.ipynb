{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "import gensim\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"..\\\\Data_Processing\\\\cleaned.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>one highlight dutch cinema moving story young ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                                            cleaned\n",
       "0           0   1  one highlight dutch cinema moving story young ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a corpus (list of lists of strings) and use it to create a Gensim Dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reviews[\"cleaned\"].apply(lambda s: s.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%time dictionary = Dictionary(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310703"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.token2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary.dfs[dictionary.token2id[\"character\"]]\n",
    "#sortedcounts = list(dictionary.dfs.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sortedcounts.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top20 = sortedcounts[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81488,\n",
       " 81622,\n",
       " 82011,\n",
       " 84207,\n",
       " 85392,\n",
       " 86891,\n",
       " 88261,\n",
       " 88502,\n",
       " 89368,\n",
       " 94283,\n",
       " 102572,\n",
       " 104036,\n",
       " 108622,\n",
       " 108744,\n",
       " 114349,\n",
       " 121608,\n",
       " 153369,\n",
       " 165999,\n",
       " 186797,\n",
       " 197009]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one 153369\n",
      "story 102572\n",
      "would 88261\n",
      "movie 186797\n",
      "like 121608\n",
      "make 89368\n",
      "time 114349\n",
      "good 108744\n",
      "see 94283\n",
      "really 82011\n",
      "well 88502\n",
      "this 108622\n",
      "film 165999\n",
      "the 197009\n",
      "even 85392\n",
      "character 104036\n",
      "get 81488\n",
      "scene 81622\n",
      "much 84207\n",
      "great 86891\n"
     ]
    }
   ],
   "source": [
    "#for k,v in dictionary.dfs.items():\n",
    "#    if v in top20:\n",
    "#        print (list(dictionary.token2id.keys())[k],v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use dictionary functionality to remove word extremes\n",
    "# Remove words that occur in fewer than 10 documents or more than 60% of documents\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a corpus that is the vectorized version of the list of list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%time corpus = [dictionary.doc2bow(text) for text in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This functionality is not supported with multicore\n",
    "# Create callbacks so we get metrics during progress\n",
    "#from gensim.models.callbacks import PerplexityMetric\n",
    "#from gensim.models.callbacks import DiffMetric\n",
    "#from gensim.models.callbacks import CoherenceMetric\n",
    "#from gensim.models.callbacks import ConvergenceMetric\n",
    "\n",
    "#callbacklist = [PerplexityMetric(corpus=corpus2, logger='shell'),\n",
    "#           DiffMetric(logger='shell'),\n",
    "#           CoherenceMetric(corpus=corpus2, dictionary = dictionary, logger='shell'),\n",
    "#           ConvergenceMetric(logger='shell')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#lda = gensim.models.ldamodel.LdaModel(corpus=corpus2, id2word=dictionary, num_topics=20, update_every=0, passes=20, callbacks =callbacklist)\n",
    "#lda = gensim.models.LdaMulticore(workers=2,corpus=corpus2, id2word=dictionary, num_topics=20, iterations=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results so they can be used to display interactively later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('movies_corpus.pkl', 'wb'))\n",
    "dictionary.save('movies_dictionary.gensim')\n",
    "##lda.save('movies20topics.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#lda = gensim.models.ldamodel.LdaModel(corpus=corpus2, id2word=dictionary, num_topics=20, update_every=0, passes=20, callbacks =callbacklist)\n",
    "#lda50 = gensim.models.LdaMulticore(workers=2,corpus=corpus2, id2word=dictionary, num_topics=50, iterations=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.064*\"movie\" + 0.020*\"like\" + 0.018*\"good\" + 0.017*\"really\" + 0.014*\"the\" + 0.011*\"one\" + 0.010*\"great\" + 0.010*\"time\" + 0.010*\"see\" + 0.009*\"scene\"')\n",
      "(1, '0.154*\"film\" + 0.025*\"the\" + 0.011*\"good\" + 0.009*\"one\" + 0.008*\"time\" + 0.008*\"well\" + 0.007*\"action\" + 0.006*\"this\" + 0.006*\"great\" + 0.006*\"like\"')\n",
      "(2, '0.027*\"movie\" + 0.013*\"one\" + 0.010*\"good\" + 0.010*\"guy\" + 0.010*\"the\" + 0.009*\"like\" + 0.007*\"get\" + 0.006*\"great\" + 0.006*\"well\" + 0.006*\"actor\"')\n",
      "(3, '0.037*\"horror\" + 0.027*\"the\" + 0.008*\"one\" + 0.007*\"scary\" + 0.007*\"like\" + 0.007*\"original\" + 0.006*\"king\" + 0.006*\"film\" + 0.006*\"jack\" + 0.006*\"version\"')\n",
      "(4, '0.052*\"bond\" + 0.014*\"connery\" + 0.013*\"james\" + 0.010*\"one\" + 0.010*\"the\" + 0.009*\"sean\" + 0.008*\"moore\" + 0.007*\"action\" + 0.007*\"villain\" + 0.007*\"roger\"')\n",
      "(5, '0.021*\"the\" + 0.013*\"effect\" + 0.008*\"one\" + 0.008*\"special\" + 0.007*\"movie\" + 0.006*\"scene\" + 0.006*\"tarzan\" + 0.006*\"like\" + 0.005*\"warrior\" + 0.005*\"and\"')\n",
      "(6, '0.017*\"film\" + 0.016*\"the\" + 0.009*\"war\" + 0.008*\"western\" + 0.006*\"battle\" + 0.005*\"one\" + 0.005*\"warrior\" + 0.005*\"time\" + 0.004*\"character\" + 0.004*\"horse\"')\n",
      "(7, '0.081*\"book\" + 0.026*\"read\" + 0.021*\"movie\" + 0.018*\"the\" + 0.011*\"film\" + 0.011*\"novel\" + 0.010*\"story\" + 0.010*\"character\" + 0.008*\"would\" + 0.008*\"much\"')\n",
      "(8, '0.012*\"the\" + 0.012*\"alien\" + 0.010*\"world\" + 0.008*\"human\" + 0.008*\"film\" + 0.007*\"planet\" + 0.006*\"space\" + 0.006*\"one\" + 0.006*\"like\" + 0.006*\"sci-fi\"')\n",
      "(9, '0.013*\"the\" + 0.011*\"gang\" + 0.009*\"one\" + 0.008*\"hitchcock\" + 0.007*\"get\" + 0.006*\"murder\" + 0.005*\"wife\" + 0.005*\"man\" + 0.005*\"thriller\" + 0.005*\"killer\"')\n",
      "(10, '0.011*\"the\" + 0.006*\"one\" + 0.005*\"film\" + 0.005*\"john\" + 0.004*\"role\" + 0.004*\"man\" + 0.004*\"novel\" + 0.004*\"woman\" + 0.003*\"play\" + 0.003*\"robert\"')\n",
      "(11, '0.024*\"vampire\" + 0.009*\"life\" + 0.009*\"bella\" + 0.007*\"the\" + 0.007*\"cruise\" + 0.006*\"get\" + 0.005*\"film\" + 0.005*\"one\" + 0.005*\"see\" + 0.004*\"family\"')\n",
      "(12, '0.073*\"movie\" + 0.020*\"one\" + 0.015*\"the\" + 0.014*\"this\" + 0.014*\"time\" + 0.013*\"seen\" + 0.012*\"see\" + 0.012*\"film\" + 0.012*\"ever\" + 0.011*\"best\"')\n",
      "(13, '0.025*\"war\" + 0.019*\"the\" + 0.009*\"get\" + 0.008*\"movie\" + 0.007*\"german\" + 0.007*\"one\" + 0.007*\"like\" + 0.006*\"soldier\" + 0.005*\"men\" + 0.005*\"alien\"')\n",
      "(14, '0.019*\"performance\" + 0.016*\"best\" + 0.014*\"great\" + 0.013*\"the\" + 0.012*\"oscar\" + 0.012*\"spielberg\" + 0.011*\"role\" + 0.011*\"one\" + 0.011*\"film\" + 0.011*\"actor\"')\n",
      "(15, '0.024*\"movie\" + 0.020*\"the\" + 0.018*\"character\" + 0.011*\"film\" + 0.009*\"plot\" + 0.008*\"good\" + 0.008*\"like\" + 0.008*\"would\" + 0.008*\"bad\" + 0.007*\"story\"')\n",
      "(16, '0.026*\"film\" + 0.012*\"the\" + 0.009*\"life\" + 0.009*\"one\" + 0.007*\"story\" + 0.007*\"character\" + 0.007*\"people\" + 0.006*\"this\" + 0.005*\"way\" + 0.005*\"world\"')\n",
      "(17, '0.029*\"the\" + 0.022*\"film\" + 0.009*\"performance\" + 0.009*\"character\" + 0.009*\"scene\" + 0.008*\"one\" + 0.007*\"story\" + 0.006*\"well\" + 0.005*\"great\" + 0.005*\"version\"')\n",
      "(18, '0.009*\"the\" + 0.008*\"black\" + 0.008*\"white\" + 0.008*\"film\" + 0.005*\"one\" + 0.005*\"would\" + 0.004*\"woman\" + 0.004*\"like\" + 0.003*\"make\" + 0.003*\"man\"')\n",
      "(19, '0.017*\"the\" + 0.013*\"child\" + 0.009*\"kid\" + 0.008*\"disney\" + 0.007*\"girl\" + 0.007*\"family\" + 0.007*\"young\" + 0.007*\"love\" + 0.007*\"boy\" + 0.007*\"story\"')\n"
     ]
    }
   ],
   "source": [
    "#topics_20 = lda.print_topics(num_words=10)\n",
    "#for topic in topics_20:\n",
    "#    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, '0.035*\"girl\" + 0.020*\"moore\" + 0.010*\"movie\" + 0.007*\"like\" + 0.006*\"and\" + 0.006*\"get\" + 0.006*\"scene\" + 0.005*\"the\" + 0.005*\"hudson\" + 0.005*\"mcadams\"')\n",
      "(29, '0.049*\"jack\" + 0.031*\"killer\" + 0.021*\"the\" + 0.016*\"serial\" + 0.008*\"fbi\" + 0.007*\"movie\" + 0.007*\"one\" + 0.005*\"subway\" + 0.005*\"marius\" + 0.005*\"film\"')\n",
      "(32, '0.026*\"film\" + 0.021*\"character\" + 0.020*\"the\" + 0.014*\"story\" + 0.009*\"one\" + 0.006*\"make\" + 0.005*\"viewer\" + 0.005*\"work\" + 0.004*\"time\" + 0.004*\"much\"')\n",
      "(33, '0.089*\"book\" + 0.030*\"movie\" + 0.030*\"read\" + 0.012*\"the\" + 0.012*\"would\" + 0.011*\"novel\" + 0.008*\"story\" + 0.007*\"like\" + 0.007*\"much\" + 0.007*\"character\"')\n",
      "(11, '0.020*\"western\" + 0.010*\"film\" + 0.008*\"the\" + 0.007*\"coen\" + 0.007*\"yuma\" + 0.006*\"steinfeld\" + 0.006*\"shane\" + 0.006*\"vaughn\" + 0.005*\"3:10\" + 0.005*\"french\"')\n",
      "(16, '0.028*\"the\" + 0.021*\"scary\" + 0.018*\"movie\" + 0.013*\"horror\" + 0.009*\"phantom\" + 0.008*\"nemo\" + 0.007*\"slug\" + 0.007*\"child\" + 0.006*\"scared\" + 0.005*\"hooper\"')\n",
      "(23, '0.043*\"tom\" + 0.019*\"ripley\" + 0.013*\"the\" + 0.011*\"maguire\" + 0.011*\"film\" + 0.010*\"character\" + 0.010*\"clarice\" + 0.008*\"starling\" + 0.007*\"damon\" + 0.007*\"dan\"')\n",
      "(14, '0.011*\"love\" + 0.011*\"the\" + 0.008*\"life\" + 0.006*\"scene\" + 0.006*\"character\" + 0.005*\"one\" + 0.005*\"woman\" + 0.005*\"film\" + 0.004*\"young\" + 0.004*\"she\"')\n",
      "(1, '0.111*\"spielberg\" + 0.029*\"steven\" + 0.018*\"film\" + 0.018*\"schindler\" + 0.014*\"williams\" + 0.012*\"munich\" + 0.010*\"the\" + 0.010*\"jurassic\" + 0.009*\"list\" + 0.009*\"great\"')\n",
      "(48, '0.020*\"movie\" + 0.019*\"the\" + 0.018*\"film\" + 0.016*\"scene\" + 0.016*\"action\" + 0.013*\"character\" + 0.010*\"much\" + 0.010*\"good\" + 0.008*\"story\" + 0.008*\"time\"')\n",
      "(25, '0.012*\"jane\" + 0.009*\"the\" + 0.008*\"movie\" + 0.008*\"one\" + 0.007*\"time\" + 0.006*\"get\" + 0.006*\"hotel\" + 0.006*\"shark\" + 0.005*\"devil\" + 0.005*\"film\"')\n",
      "(9, '0.012*\"the\" + 0.009*\"human\" + 0.009*\"film\" + 0.007*\"world\" + 0.006*\"time\" + 0.006*\"verhoeven\" + 0.006*\"one\" + 0.005*\"story\" + 0.005*\"future\" + 0.004*\"like\"')\n",
      "(4, '0.014*\"the\" + 0.009*\"action\" + 0.007*\"film\" + 0.006*\"german\" + 0.006*\"war\" + 0.005*\"one\" + 0.005*\"mission\" + 0.004*\"russian\" + 0.003*\"warrior\" + 0.003*\"hero\"')\n",
      "(34, '0.024*\"the\" + 0.022*\"jackson\" + 0.019*\"movie\" + 0.018*\"wizard\" + 0.014*\"potter\" + 0.014*\"harry\" + 0.013*\"story\" + 0.011*\"film\" + 0.010*\"hobbit\" + 0.009*\"tolkien\"')\n",
      "(2, '0.021*\"the\" + 0.016*\"film\" + 0.008*\"one\" + 0.006*\"john\" + 0.006*\"role\" + 0.005*\"cast\" + 0.005*\"performance\" + 0.005*\"best\" + 0.005*\"classic\" + 0.004*\"robert\"')\n",
      "(7, '0.027*\"the\" + 0.021*\"original\" + 0.019*\"film\" + 0.012*\"bella\" + 0.012*\"remake\" + 0.012*\"good\" + 0.012*\"vampire\" + 0.011*\"one\" + 0.011*\"horror\" + 0.010*\"like\"')\n",
      "(18, '0.030*\"best\" + 0.023*\"film\" + 0.022*\"oscar\" + 0.015*\"the\" + 0.015*\"one\" + 0.014*\"performance\" + 0.013*\"award\" + 0.012*\"movie\" + 0.008*\"academy\" + 0.007*\"this\"')\n",
      "(49, '0.012*\"the\" + 0.011*\"film\" + 0.008*\"peter\" + 0.008*\"harry\" + 0.005*\"cogburn\" + 0.005*\"professor\" + 0.005*\"radcliffe\" + 0.005*\"one\" + 0.004*\"adventure\" + 0.004*\"rooster\"')\n",
      "(42, '0.021*\"life\" + 0.011*\"drug\" + 0.008*\"dream\" + 0.007*\"the\" + 0.006*\"stardust\" + 0.005*\"eli\" + 0.005*\"this\" + 0.005*\"world\" + 0.005*\"one\" + 0.005*\"mental\"')\n",
      "(37, '0.100*\"movie\" + 0.016*\"one\" + 0.015*\"see\" + 0.015*\"like\" + 0.014*\"the\" + 0.013*\"great\" + 0.013*\"time\" + 0.013*\"really\" + 0.013*\"good\" + 0.012*\"this\"')\n"
     ]
    }
   ],
   "source": [
    "#topics_50 = lda50.print_topics(num_words=10)\n",
    "#for topic in topics_50:\n",
    "#    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.708791945194641"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "#cm = CoherenceModel(model=lda50, corpus=corpus2, coherence='u_mass')\n",
    "#coherence = cm.get_coherence()\n",
    "#coherence\n",
    "## -1.607074887186608 for 20\n",
    "## -2.708791945194641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_SIZES = [12, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80]\n",
    "results = []\n",
    "for topic_size in TOPIC_SIZES:\n",
    "    print(datetime.datetime.today(), 'Process model for ' + str(topic_size) + ' topics')\n",
    "    ldatmp = gensim.models.LdaMulticore(workers=2,corpus=corpus2, id2word=dictionary, passes=20, num_topics=topic_size, iterations=20)\n",
    "    print(datetime.datetime.today(), 'Model created for ' + str(topic_size) + ' topics')\n",
    "    cm = CoherenceModel(model=ldatmp, corpus=corpus2, coherence='u_mass')\n",
    "    coherence_um = cm.get_coherence()\n",
    "    cm = CoherenceModel(model=ldatmp, texts=documents, coherence='c_v')\n",
    "    coherence_cv = cm.get_coherence()\n",
    "    print(datetime.datetime.today())\n",
    "    print(topic_size, coherence_um, coherence_cv)\n",
    "    results.append((topic_size, coherence_um, coherence_cv))\n",
    "    ldatmp.save('movies_topics_' + str(topic_size) + '.gensim')\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open('lda_results.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 22:08:38.798953\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
