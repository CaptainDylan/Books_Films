{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "import numpy as np\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import book_review and wiki_book_movie_ids_matching to filter out books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+pymysql://dva:DVA2019!@dvaproject.c9f0lti9xqdg.us-east-1.rds.amazonaws.com/reviews?charset=utf8', echo=False) \n",
    "\n",
    "match = pd.read_sql(\"wiki_book_movie_ids_matching\", con=engine)\n",
    "book_rev = pd.read_sql(\"book_reviews\", con=engine)\n",
    "book_rev[0:5]\n",
    "book_rev = pd.merge(book_rev, match[[\"id_goodreads\"]], left_on = \"book_id\", right_on = \"id_goodreads\") #match book_review with book-movie pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rev1= book_rev.loc[book_rev ['review_text'].notnull()].copy()   # when review text is not nan\n",
    "#strip out all the punctuation\n",
    "book_rev1['review_text'] = book_rev1.review_text.apply(lambda s: s.lower())\n",
    "book_rev1.review_text.replace({r'\\'' : r''}, regex = True, inplace = True) #clean trailing dashes\n",
    "book_rev1.review_text.replace({r'[^\\x00-\\x7f]' : r''}, regex = True, inplace = True) #remove all hex character\n",
    "book_rev1.review_text.replace({'â':'', '':'', '¥':''}, regex = True, inplace = True) #further cleaning\n",
    "book_rev1.review_text.replace({r'([^\\s\\w\\-]|_)+' : r' '}, regex=True, inplace = True)\n",
    "book_rev1.review_text.replace({r'\\--+|\\\\n|\\s\\s+' : r' '}, regex = True, inplace = True) #clean trailing dashes\n",
    "book_rev1 = book_rev1.loc[book_rev ['language']=='en']  #remove reivews written in another language\n",
    "book_rev1.review_text.replace({r'\\s\\-+\\s|[\\w\\d]\\-\\s' : r''}, regex = True, inplace = True) #clean trailing dashes\n",
    "book_rev1[0:10000].to_csv('book_rev_part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate rows\n",
    "book_rev1 = book_rev1.drop_duplicates(subset=['book_id', 'review_id', \"rating\", \"review_text\", \"language\", \"id_goodreads\" ], keep=False)\n",
    "book_rev1.review_text.replace({r'\\s\\s+' : r' '}, regex = True, inplace = True) #clean all trailing spaces\n",
    "#book_rev.drop([37233, 11082, 1250, 13065], inplace = True) #drop review without any words\n",
    "\n",
    "#book_rev[10000:20000].to_csv('book_rev_part2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove review's rating in review_text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stars = book_rev[book_rev.review_text.str.contains(r'\\d\\s\\d\\d.*\\d+\\sstars?')].copy()\n",
    "#stars.to_csv('stars_rating.csv')\n",
    "#book_rev[0:10000].to_csv('book_rev_part_before.csv')\n",
    "#book_rev.drop(book_rev.index[[37233]], inplace = True)\n",
    "#book_rev.index[book_rev['review_id']==2191718420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "book_rev1.review_text.replace({r'\\d\\s\\d\\d.*\\d+\\sstars?' : r''}, regex=True, inplace = True)\n",
    "book_rev1.review_text.replace({r'[0-9].*[0-9]\\sstars?' : r''}, regex=True, inplace = True)  # clean format 3 0 to 3 5 stars\n",
    "book_rev1.review_text.replace({r'i would\\s.*[\\d]*stars?' : r''}, regex=True, inplace = True) # clean format i would__ stars\n",
    "book_rev1.review_text.replace({r'[A-Z0-9a-z-]*\\s*stars?' : r''}, regex=True, inplace = True) # clean format 5 stars and five star\n",
    "book_rev1.review_text.replace({r'my?.*ratings?\\:?.*\\d' : r''}, regex=True, inplace = True) # clean rating\n",
    "book_rev1.review_text.replace({r'average rating of [\\d.\\s]* |[\\w]*? rating:? |my\\sratings?\\:|rating:[\\s\\w*]*\\d|\\sof five|rating:' : r''}, regex=True, inplace = True) # clean 'my rating phrase'\n",
    "book_rev1.review_text.replace({r'rating.*\\d|\\[rating.*\\]|\\d\\s\\d\\/?\\d' : r''}, regex=True, inplace = True) # clean 'my rating phrase'\n",
    "book_rev1.review_text.replace({r'\\(?paperbacks?\\)?' : r''}, regex=True, inplace = True) # clean any discussion of paperback\n",
    "book_rev1.review_text.replace({r'\\s*?ratings|rating\\s?' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'\\shardcover\\s?|hardcover|edition' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'view spoiler|hide spoiler|spoilers?' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'few\\s|these\\s|the\\s|last\\s|every\\s|\\d*\\s?pages|\\d*page\\s*?' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'http\\S+|www.\\S+' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'\\s\\s+' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'if.*link' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'link to reviews?|click link|follow\\slink\\s|youtube\\slinks?' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'books?' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "book_rev1.review_text.replace({r'movies?' : r''}, regex=True, inplace = True) # clean any mention of rating\n",
    "\n",
    "#book_rev[book_rev.review_text == '']\n",
    "book_rev1['review_text'].replace('', np.nan, inplace=True)\n",
    "book_rev1.dropna(subset=['review_text'], inplace=True)\n",
    "#book_rev1[0:10000].to_csv('book_rev_part.csv')\n",
    "#book_rev[10000:20000].to_csv('book_rev_part2.csv')\n",
    "#book_rev[book_rev['review_id'].str.contains('much')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove un-necessary story synposis from review_id = 142133155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rev1['review_text'] = book_rev1['review_text'].str.replace(r'contains\\s.*synopsis\\)','' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = book_rev1['review_text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "#stop_words = stop_words.union({'book','movie'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.apply(lambda words: [w for w in words if w not in stop_words and len(w) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = tokens.apply(lambda words: [lemmatizer.lemmatize(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rev1[\"cleaned\"] = lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert it to CSV and then use R to upload it back to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rev1.to_csv('book_review_cleaned1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
